# -*- coding: utf-8 -*-
"""AE_example.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ol_draeb0frlfpL4YjPC0Eqwvl75zfPG

An example of autoencoder implementation using MNIST data

AE can be considered a self-learner model as they map data features into the 
latent space which is later used for decoding the image.

It is important to point out that AEs are lossy when used for data compression 
and also can only work on the data that it was trained to encode and decode.

This example will demonstrate the basics of creating AE and applying to denoise 
images.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow import keras
from keras.datasets import mnist

from keras import layers

#Load data

(X_train,y_train),(X_test,y_test)=mnist.load_data()

#Prepare data
X_train=X_train.astype('float32')/255.0
X_test=X_test.astype('float32')/255.0

X_train=X_train.reshape(-1,28*28)
X_test=X_test.reshape(-1,28*28)
print(X_train.shape)
print(y_train[1:10])

#Create a simple encorder, decoder and autoencoder
encoding_dim=64
input_shape=28*28
input=keras.Input(shape=(input_shape,))
encoded=layers.Dense(encoding_dim,activation='relu')(input)
decoded=layers.Dense(input_shape,activation='sigmoid')(encoded)


#Create the autoencoder model
autoencoder=keras.Model(input,decoded)
print(autoencoder.summary())

#Create the encoder model
encoder=keras.Model(input,encoded)

#Create the decoder model
encoded_input=keras.Input(shape=(encoding_dim,))
decoded_layer=autoencoder.layers[-1]
decoder=keras.Model(encoded_input,decoded_layer(encoded_input))



#compile models
autoencoder.compile(optimizer='adam',loss='binary_crossentropy') #NOTE we are focusing on pixel to pixel conversion

#Set params
EPOCHS=50
BATCH=256
VAL_SPLIT=0.2

history=autoencoder.fit(X_train,X_train,epochs=EPOCHS,batch_size=BATCH,validation_split=0.2, shuffle=True)
epochs=history.epoch
history=history.history
print("best epoch",epochs[np.argmin(history['val_loss'])])

plt.plot(epochs,history['loss'],'-b',label='Training loss')
plt.plot(epochs,history['val_loss'],'-r',label='Val loss')
plt.legend()
plt.show()

#Explore model performance
encoded_images=encoder.predict(X_test)
decoded_images=decoder.predict(encoded_images)

#Visuale model outputs
fig,ax=plt.subplots(2,10,figsize=(20,5))

for i in range(10):
  #Encoded images
  ax[0,i].imshow(X_test[i].reshape(28,28),cmap='binary')
  #Decoded images
  ax[1,i].imshow(decoded_images[i].reshape(28,28),cmap='binary')

plt.show()

#Create a deep autoencoder

input_shape=28*28

input=keras.Input(shape=(input_shape,))
encoded=layers.Dense(256,activation='relu')(input)
encoded=layers.Dense(128,activation='relu')(encoded)
encoded=layers.Dense(64,activation='relu')(encoded)

encoded_latent=layers.Dense(32,activation='relu')(encoded)

decoded=layers.Dense(64,activation='relu')(encoded_latent)
decoded=layers.Dense(128,activation='relu')(decoded)
decoded=layers.Dense(256,activation='relu')(decoded)
decoded=layers.Dense(input_shape,activation='sigmoid')(decoded)

#Create the autoencoder model
autoencoder=keras.Model(input,decoded)

print(autoencoder.summary())

#Create the encoder model
encoder=keras.Model(input,encoded_latent)

#Create the decoder model
encoded_input=keras.Input(shape=(32,))
decoded_layer=autoencoder.layers[-4](encoded_input)
decoded_layer=autoencoder.layers[-3](decoded_layer)
decoded_layer=autoencoder.layers[-2](decoded_layer)
decoded_layer=autoencoder.layers[-1](decoded_layer)
decoder=keras.Model(encoded_input,decoded_layer)



#compile models
autoencoder.compile(optimizer='adam',loss='binary_crossentropy') #NOTE we are focusing on pixel to pixel conversion

history=autoencoder.fit(X_train,X_train,epochs=EPOCHS,batch_size=BATCH,validation_split=0.2, shuffle=True)
epochs=history.epoch
history=history.history
print("best epoch",epochs[np.argmin(history['val_loss'])])

plt.plot(epochs,history['loss'],'-b',label='Training loss')
plt.plot(epochs,history['val_loss'],'-r',label='Val loss')
plt.legend()
plt.show()

#Explore model performance
encoded_images=encoder.predict(X_test)
decoded_images=decoder.predict(encoded_images)
autoencoder_images=autoencoder.predict(X_test) #Instead of splitting model into encoder and decoder

#Visuale model outputs
fig,ax=plt.subplots(2,10,figsize=(20,5))

for i in range(10):
  #Encoded images
  ax[0,i].imshow(X_test[i].reshape(28,28),cmap='binary')
  #Decoded images
  ax[1,i].imshow(decoded_images[i].reshape(28,28),cmap='binary')


plt.show()

#Inspect autoencoder images
  fig,ax=plt.subplots(2,10,figsize=(20,5))
  for i in range(10): 
    #Visualise the encoded images
    ax[0,i].imshow(ecoded_images[i].reshape(4,8),cmap='binary') #Note there are 32 points in this layer
    ax[1,i].imshow(autoencoder_images[i].reshape(28,28),cmap='binary')

  plt.show()

#Create a sparse model to reduce overfitting and ensure the useful feature extraction
#Create a deep sparse autoencoder

input_shape=28*28

input=keras.Input(shape=(input_shape,))
encoded=layers.Dense(256,activation='relu', activity_regularizer=keras.regularizers.l1(10e-6))(input)
encoded=layers.Dense(128,activation='relu',activity_regularizer=keras.regularizers.l1(10e-6))(encoded)
encoded=layers.Dense(64,activation='relu',activity_regularizer=keras.regularizers.l1(10e-6))(encoded)

encoded_latent=layers.Dense(32,activation='relu')(encoded)

decoded=layers.Dense(64,activation='relu')(encoded_latent) #Note dense layer does not necessarily needs to be a mirror image of encoder
decoded=layers.Dense(128,activation='relu')(decoded)
decoded=layers.Dense(256,activation='relu')(decoded)
decoded=layers.Dense(input_shape,activation='sigmoid')(decoded)

#Create the autoencoder model
reg_autoencoder=keras.Model(input,decoded)

print(reg_autoencoder.summary())

#Create the encoder model
encoder_reg=keras.Model(input,encoded_latent)

#Create the decoder model
encoded_input=keras.Input(shape=(32,))
decoded_layer=reg_autoencoder.layers[-4](encoded_input)
decoded_layer=reg_autoencoder.layers[-3](decoded_layer)
decoded_layer=reg_autoencoder.layers[-2](decoded_layer)
decoded_layer=reg_autoencoder.layers[-1](decoded_layer)
decoder=keras.Model(encoded_input,decoded_layer)



#compile models
reg_autoencoder.compile(optimizer='adam',loss='binary_crossentropy') #NOTE we are focusing on pixel to pixel conversion

history=reg_autoencoder.fit(X_train,X_train,epochs=EPOCHS,batch_size=BATCH,validation_split=0.2, shuffle=True)
epochs=history.epoch
history=history.history
print("best epoch",epochs[np.argmin(history['val_loss'])])

plt.plot(epochs,history['loss'],'-b',label='Training loss')
plt.plot(epochs,history['val_loss'],'-r',label='Val loss')
plt.legend()
plt.show()

#Explore model performance
encoded_images=encoder_reg.predict(X_test)
decoded_images=decoder.predict(encoded_images)
autoencoder_images=reg_autoencoder.predict(X_test) #Instead of splitting model into encoder and decoder

#Visuale model outputs
fig,ax=plt.subplots(2,10,figsize=(20,5))

for i in range(10):
  #Encoded images
  ax[0,i].imshow(X_test[i].reshape(28,28),cmap='binary')
  #Decoded images
  ax[1,i].imshow(decoded_images[i].reshape(28,28),cmap='binary')


plt.show()

#Inspect autoencoder images
  fig,ax=plt.subplots(2,10,figsize=(20,5))
  for i in range(10): 
    #Visualise the encoded images
    ax[0,i].imshow(ecoded_images[i].reshape(4,8),cmap='binary') #Note there are 32 points in this layer
    ax[1,i].imshow(autoencoder_images[i].reshape(28,28),cmap='binary')

  plt.show()

#Example of data denoising using ConvNets

#Load data

(X_train,y_train),(X_test,y_test)=mnist.load_data()

#Prepare data
X_train=X_train.astype('float32')/255.0
X_train=X_train.reshape(-1,28,28,1)
X_test=X_test.astype('float32')/255.0
X_test=X_test.reshape(-1,28,28,1)

#Add noise to the data
noise=0.5
X_train_noise=X_train+noise*np.random.normal(loc=0.0,scale=1.0,size=X_train.shape)
X_train_noise=np.clip(X_train_noise,0.0,1.0) #ensure that the range remains within the scaled interval
X_test_noise=X_test+noise*np.random.normal(loc=0.0,scale=1.0,size=X_test.shape)
X_test_noise=np.clip(X_test_noise,0.0,1.0)

print(X_train.shape)
print(X_test.shape)

input_shape=(28,28,1)

input=keras.Input(shape=input_shape)

encoded=layers.Conv2D(16,(3,3),padding='same',activation='relu')(input)
encoded=layers.MaxPooling2D((2,2),padding='same')(encoded)
encoded=layers.Conv2D(8,(3,3),padding='same',activation='relu')(encoded)
encoded=layers.MaxPooling2D((2,2),padding='same')(encoded)
encoded=layers.Conv2D(8,(3,3),padding='same',activation='relu')(encoded)

encoded_latent=layers.MaxPooling2D((2,2),padding='same')(encoded)

decoded=layers.Conv2D(8,(3,3),padding='same',activation='relu')(encoded_latent)
decoded=layers.UpSampling2D((2,2))(decoded)
decoded=layers.Conv2D(8,(3,3),padding='same',activation='relu')(decoded)
decoded=layers.UpSampling2D((2,2))(decoded)
decoded=layers.Conv2D(16,(3,3),padding='valid',activation='relu')(decoded) #Note final layer needs to have a valid padding
decoded=layers.UpSampling2D((2,2))(decoded)

decoded=layers.Conv2D(1,(3,3),padding='same',activation='sigmoid')(decoded)
#Create the autoencoder model
autoencoder=keras.Model(input,decoded)

print(autoencoder.summary())

#compile models

#Create the encoder model
encoder=keras.Model(input,encoded_latent)

#Create the decoder model
encoded_input=keras.Input(shape=(4,4,8))
decoded_layer=autoencoder.layers[-7](encoded_input)
decoded_layer=autoencoder.layers[-6](decoded_layer)
decoded_layer=autoencoder.layers[-5](decoded_layer)
decoded_layer=autoencoder.layers[-4](decoded_layer)
decoded_layer=autoencoder.layers[-3](decoded_layer)
decoded_layer=autoencoder.layers[-2](decoded_layer)
decoded_layer=autoencoder.layers[-1](decoded_layer)
decoder=keras.Model(encoded_input,decoded_layer)



#compile models
autoencoder.compile(optimizer='adam',loss='binary_crossentropy') #NOTE we are focusing on pixel to pixel conversion

history=autoencoder.fit(X_train_noise,X_train_noise,epochs=EPOCHS,batch_size=BATCH,validation_split=0.2, shuffle=True)
epochs=history.epoch
history=history.history
print("best epoch",epochs[np.argmin(history['val_loss'])])

plt.plot(epochs,history['loss'],'-b',label='Training loss')
plt.plot(epochs,history['val_loss'],'-r',label='Val loss')
plt.legend()
plt.show()

#Explore model performance
encoded_images=encoder.predict(X_test)
decoded_images=decoder.predict(encoded_images)
autoencoder_images=autoencoder.predict(X_test) #Instead of splitting model into encoder and decoder

#Visuale model outputs
fig,ax=plt.subplots(2,10,figsize=(20,5))

for i in range(10):
  #Encoded images
  ax[0,i].imshow(X_test_noise[i].reshape(28,28),cmap='binary')
  #Decoded images
  ax[1,i].imshow(decoded_images[i].reshape(28,28),cmap='binary')


plt.show()

#Inspect autoencoder images
  fig,ax=plt.subplots(2,10,figsize=(20,5))
  for i in range(10): 
    #Visualise the encoded images
    ax[0,i].imshow(encoded_images[i].reshape(16,8),cmap='binary') #Note there are 128 points in this layer
    ax[1,i].imshow(autoencoder_images[i].reshape(28,28),cmap='binary')

  plt.show()